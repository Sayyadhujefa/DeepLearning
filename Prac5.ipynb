{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf24mMCAmBIbirqq1XZSNq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayyadhujefa/DeepLearning/blob/main/Prac5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "louSfJIIaBSW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
        "import numpy as np\n",
        "import collections\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- a. Data Preparation ---\n",
        "# Sample corpus\n",
        "corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "The dog barks, and the fox runs away.\n",
        "A quick brown rabbit also jumps.\n",
        "\"\"\"\n",
        ""
      ],
      "metadata": {
        "id": "zcgUAs-9aDbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the corpus\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([corpus])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1 # +1 for padding/unknown words\n",
        "print(f\"Vocabulary: {word_index}\")\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "# Convert corpus to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences([corpus])[0]\n",
        "print(f\"Sequences: {sequences}\")\n",
        "# --- b. Generate Training Data (Skip-gram is used here for demonstration, CBOW concept is similar) ---\n",
        "# For CBOW, we'd typically create pairs of (context_words, target_word)\n",
        "# Here, we use skipgrams for simplicity as it generates pairs from sequences.\n",
        "# skipgrams returns pairs of (target_word, context_word)\n",
        "# Parameters for skipgrams\n",
        "window_size = 2 # Context window size\n",
        "# Note: For true CBOW, you'd structure this differently, but skipgrams is often used to generate pairs for word2vec-like models.\n",
        "# We will generate pairs of (target_word, context_word) using skipgrams for now,\n",
        "# and then adapt it to mimic CBOW's prediction goal.\n",
        "# A typical CBOW implementation involves averaging context embeddings.\n",
        "# A simplified approach to get CBOW data structure:"
      ],
      "metadata": {
        "id": "6hx933YIaI8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each word, gather its context.\n",
        "# Example: \"The quick brown fox\" -> target: \"brown\", context: [\"The\", \"quick\", \"fox\"]\n",
        "data = []\n",
        "target = []\n",
        "context_window = 2\n",
        "# Iterate through the sequences\n",
        "for i, word in enumerate(sequences):\n",
        "      context_start = max(0, i - context_window)\n",
        "      context_end = min(len(sequences), i + context_window + 1)\n",
        "      context = sequences[context_start:i] + sequences[i+1:context_end]\n",
        "# Ensure context is not empty\n",
        "if context:\n",
        "# For CBOW, we want to predict the word 'word' from 'context'\n",
        "# We can represent context by averaging its embeddings later, or use its indices\n",
        "# Let's prepare data where input is context indices, and target is the word index\n",
        "# For simplicity in Keras, we might one-hot encode contexts or average embeddings\n",
        "# A common simplification for Keras is to use a multi-hot encoding of context\n",
        "# or directly use skipgrams pairs and adapt the model.\n",
        "# Let's stick to generating data in a way that the model can learn the prediction.\n",
        "# A typical CBOW structure in Keras: Input (context word indices) -> Embedding ->Average -> Dense -> Output\n",
        "# For demonstration, let's create pairs where target is 'word' and input is a context word from 'context'\n",
        "# This is closer to Skip-gram but can be adapted.\n",
        "# To truly implement CBOW, one would average context embeddings.\n",
        "# We'll use a simplified model that predicts target from individual context words, then can be modified.\n",
        "# Let's generate pairs of (context_word_index, target_word_index)\n",
        "    for context_word_index in context:\n",
        "        data.append(context_word_index)\n",
        "        target.append(word)\n",
        ""
      ],
      "metadata": {
        "id": "ZiQ6c3o-aNfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to numpy arrays\n",
        "data = np.array(data)\n",
        "target = np.array(target)\n",
        "print(f\"\\nGenerated context-target pairs (simplified): {len(data)} pairs\")\n",
        "# print(f\"Example pair (context_word_index, target_word_index): ({data[0]}, {target[0]})\")"
      ],
      "metadata": {
        "id": "7U4nafR7aVQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- c. Train Model ---\n",
        "embedding_dim = 10 # Dimension of the word embeddings\n",
        "# CBOW Model: Predict target word from context words\n",
        "# Input layer will take context word index\n",
        "context_input = Input(shape=(1,), name='context_input')\n",
        "# Embedding layer: Maps word indices to dense vectors\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "name='word_embedding')\n",
        "context_embedding = embedding_layer(context_input) # Embeddings for context words\n",
        "# We need to aggregate context embeddings. In true CBOW, we average them.\n",
        "# For Keras, this is often done implicitly or by custom layers.\n"
      ],
      "metadata": {
        "id": "soW55Mf5aiZ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = Dense(vocab_size, activation='softmax', name='output_layer')\n",
        "output_probs = output_layer(context_embedding)"
      ],
      "metadata": {
        "id": "NbIdivQbcJrv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Re-preparing data for actual CBOW structure:\n",
        "# For each word, gather its context indices.\n",
        "# Input: [context_word1_idx, context_word2_idx, ...]\n",
        "# Target: target_word_idx\n",
        "data_cbow = []\n",
        "target_cbow = []\n",
        "sequences=[]\n",
        "context_indices=[]\n",
        "for i, word in enumerate(sequences):\n",
        "      context_start = max(0, i - context_window)\n",
        "      context_end = min(len(sequences), i + context_window + 1)\n",
        "      context_indices = sequences[context_start:i] + sequences[i+1:context_end]\n",
        "if context_indices:\n",
        "# Pad context if needed to have a fixed length, or handle variable length\n",
        "# For simplicity, let's assume a fixed context window size that we can pad\n",
        "# Here, we'll use the actual context and average.\n",
        "      data_cbow.append(context_indices)\n",
        "      target_cbow.append(word)\n",
        "# Convert to numpy arrays\n",
        "data_cbow = np.array(data_cbow)\n",
        "target_cbow = np.array(target_cbow)\n",
        "print(f\"\\nCBOW data shape: {data_cbow.shape}\") # (num_samples, avg_num_context_words)\n",
        "print(f\"CBOW target shape: {target_cbow.shape}\") # (num_samples,)\n",
        "# Building the CBOW model architecture\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qproskr9cQt5",
        "outputId": "0d5bcb02-c13d-45f8-b4a9-f51c434ce3af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CBOW data shape: (0,)\n",
            "CBOW target shape: (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# --- CBOW model architecture ---\n",
        "cbow_input = Input(shape=(None,), name='cbow_input')  # variable number of context words\n",
        "\n",
        "# Embedding layer\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='word_embedding')\n",
        "embedded_contexts = embedding(cbow_input)  # (batch_size, num_context_words, embedding_dim)\n",
        "\n",
        "# Average the embeddings\n",
        "def average_embeddings(x):\n",
        "    return K.mean(x, axis=1)\n",
        "\n",
        "averaged_context = Lambda(average_embeddings, output_shape=(embedding_dim,), name='average_context')(embedded_contexts)\n",
        "\n",
        "# Output layer — THIS is where you made the mistake before\n",
        "cbow_output = Dense(vocab_size, activation='softmax', name='output_layer')(averaged_context)\n",
        "\n",
        "# Build and compile the model\n",
        "cbow_model = Model(inputs=cbow_input, outputs=cbow_output)\n",
        "cbow_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "cbow_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "JKirVhBbdro_",
        "outputId": "d85b5753-515d-4b89-8306-542518b4c141"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ cbow_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ word_embedding (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)       │        \u001b[38;5;34m50,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_context (\u001b[38;5;33mLambda\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │        \u001b[38;5;34m55,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ cbow_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ word_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_context (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,000\u001b[0m (410.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,000</span> (410.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,000\u001b[0m (410.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,000</span> (410.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CBOW model\n",
        "cbow_model = Model(inputs=cbow_input, outputs=cbow_output)\n",
        "cbow_model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy', # Use sparse because target is integer index\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6QsNL2dSf0GO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example fixed value (you can compute dynamically too)\n",
        "max_context_len = 4\n",
        "vocab_size = 5000\n",
        "embedding_dim = 10\n",
        "\n",
        "# Define model layers\n",
        "context_input = Input(shape=(max_context_len,), name='context_input')\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='word_embedding')(context_input)\n",
        "context_avg = Lambda(lambda x: tf.reduce_mean(x, axis=1))(embedding_layer)\n",
        "output = Dense(vocab_size, activation='softmax', name='output')(context_avg)\n",
        "\n",
        "cbow_model = Model(inputs=context_input, outputs=output)\n",
        "cbow_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cbow_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "0WLOTURxf49m",
        "outputId": "6ad41f5f-2bc2-4204-ad0e-bcce8c0ba7a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ context_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ word_embedding (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │        \u001b[38;5;34m50,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │        \u001b[38;5;34m55,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ context_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ word_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,000\u001b[0m (410.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,000</span> (410.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,000\u001b[0m (410.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,000</span> (410.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwJp5_W5f85z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}